<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EngageSense: Real-Time Audio Engagement</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.3.0/css/bootstrap.min.css" async>
    <script src="https://unpkg.com/wavesurfer.js" defer></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js" defer></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs" defer></script>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <!-- Intro Page -->
    <div class="intro-page" id="introPage">
        <div class="hero">
            <h1>Welcome to EngageSense</h1>
            <p>Your tool for Real-Time Audio Engagement Analysis.</p>
            <button id="startBtn" class="btn btn-success" aria-label="Get Started">Get Started</button>
        </div>
    </div>

    <!-- Main Page -->
    <div class="main-container container text-center" id="mainContainer">
        <header>
            <h1>EngageSense: Real-Time Audio Engagement</h1>
        </header>

        <h3>Upload or Record Audio</h3>
        <div class="btn-group" role="group">
            <button class="btn btn-success" id="recordBtn">Record Audio</button>
            <button class="btn btn-light" id="uploadBtn">Upload Audio</button>
            <input type="file" id="fileInput" accept="audio/*" class="d-none" />
            <button class="btn btn-danger" id="stopBtn" disabled>Stop</button>
            <button class="btn btn-primary" id="analyzeBtn">Analyze</button>
        </div>

        <!-- Progress and Waveform -->
        <div id="progress" class="progress bg-light">
            <div class="progress-bar progress-bar-striped progress-bar-animated" style="width: 0%" id="progressBar"></div>
        </div>
        <div id="waveform"></div>

        <!-- Results -->
        <div class="results">
            <h3>Analysis Results</h3>
            <div id="feedback">Awaiting Analysis...</div>
            <canvas id="engagementChart" width="400" height="200"></canvas>
        </div>
    </div>

    <!-- JavaScript -->
    <script>
        const startBtn = document.getElementById("startBtn");
        const introPage = document.getElementById("introPage");
        const mainContainer = document.getElementById("mainContainer");
        const recordBtn = document.getElementById("recordBtn");
        const stopBtn = document.getElementById("stopBtn");
        const uploadBtn = document.getElementById("uploadBtn");
        const analyzeBtn = document.getElementById("analyzeBtn");
        const fileInput = document.getElementById("fileInput");
        const feedback = document.getElementById("feedback");
        const progressBar = document.getElementById("progressBar");

        let audioChunks = [];
        let mediaRecorder;
        let wavesurfer;
        let sentimentModel;

        // Show Main Page
        startBtn.addEventListener("click", () => {
            introPage.style.display = "none";
            mainContainer.style.display = "block";
            loadModel();
        });

        // Initialize WaveSurfer
        wavesurfer = WaveSurfer.create({
            container: "#waveform",
            waveColor: "lime",
            progressColor: "green",
            cursorColor: "red",
            barWidth: 2,
            responsive: true
        });

        // Load TensorFlow.js Sentiment Model
        async function loadModel() {
            sentimentModel = await tf.loadLayersModel('https://storage.googleapis.com/tfjs-models/tfjs/sentiment_cnn_v1/model.json');
            console.log("Model Loaded Successfully");
        }

        // Record Audio
        recordBtn.addEventListener("click", () => {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    mediaRecorder = new MediaRecorder(stream);
                    audioChunks = [];
                    mediaRecorder.start();
                    recordBtn.disabled = true;
                    stopBtn.disabled = false;

                    mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
                })
                .catch(err => console.error("Error accessing microphone:", err));
        });

        stopBtn.addEventListener("click", () => {
            mediaRecorder.stop();
            recordBtn.disabled = false;
            stopBtn.disabled = true;

            mediaRecorder.onstop = () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                wavesurfer.loadBlob(audioBlob);
                analyzeAudio(audioBlob);
            };
        });

        // Upload Audio
        uploadBtn.addEventListener("click", () => fileInput.click());

        fileInput.addEventListener("change", () => {
            const file = fileInput.files[0];
            if (file) {
                wavesurfer.loadBlob(file);
                analyzeAudio(file);
            }
        });

        // Analyze Audio
        async function analyzeAudio(file) {
            progressBar.style.width = "50%";
            feedback.innerText = "Analyzing...";

            // Simulate analysis logic
            const randomEngagement = [Math.random() * 100, Math.random() * 100, Math.random() * 100, Math.random() * 100];
            progressBar.style.width = "100%";
            updateChart(randomEngagement);

            feedback.innerHTML = `
                <strong>Physical:</strong> ${randomEngagement[0].toFixed(2)}%<br>
                <strong>Emotional:</strong> ${randomEngagement[1].toFixed(2)}%<br>
                <strong>Mental:</strong> ${randomEngagement[2].toFixed(2)}%<br>
                <strong>Spiritual:</strong> ${randomEngagement[3].toFixed(2)}%
            `;
        }

        // Update Chart
        function updateChart(data) {
            const ctx = document.getElementById("engagementChart").getContext("2d");
            new Chart(ctx, {
                type: "bar",
                data: {
                    labels: ["Physical", "Emotional", "Mental", "Spiritual"],
                    datasets: [{
                        label: "Engagement Metrics",
                        data: data,
                        backgroundColor: ["#0f0", "#ff0", "#00f", "#f00"]
                    }]
                }
            });
        }
    </script>
</body>
</html>
