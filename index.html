<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EngageSense: Real-Time Audio Engagement</title>
    <script src="https://unpkg.com/wavesurfer.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script src="https://unpkg.com/meyda/dist/meyda.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jspdf/2.4.0/jspdf.umd.min.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #121212;
            color: #ffffff;
            margin: 0;
            padding: 0;
        }
        header {
            text-align: center;
            background: #1f1f1f;
            padding: 20px;
            font-size: 26px;
            font-weight: bold;
        }
        .container {
            padding: 20px;
            text-align: center;
        }
        .waveform-container {
            margin: 20px auto;
            width: 80%;
        }
        button {
            margin: 10px;
            padding: 10px 20px;
            border: none;
            cursor: pointer;
            font-size: 16px;
            border-radius: 5px;
            color: #fff;
            background-color: #28a745;
        }
        button:hover {
            background-color: #218838;
        }
        .stop {
            background-color: #dc3545;
        }
        canvas {
            margin: 20px auto;
            width: 80%;
            max-width: 800px;
        }
        .metrics p {
            margin: 10px 0;
            font-size: 18px;
        }
        .progress {
            margin: 20px auto;
            width: 80%;
            height: 10px;
            background: #333;
            border-radius: 5px;
            overflow: hidden;
        }
        .progress div {
            width: 0;
            height: 100%;
            background: #0f0;
            transition: width 0.5s ease;
        }
    </style>
</head>
<body>
<header>EngageSense: Real-Time Audio Engagement</header>

<div class="container">
    <h2>Upload or Record Audio</h2>
    <input type="file" id="audio-upload" accept="audio/*">
    <button onclick="uploadAudio()">Upload</button>
    <button onclick="startRecording()">Record Audio</button>
    <button class="stop" onclick="stopRecording()" disabled>Stop</button>
    
    <div class="waveform-container"><div id="waveform"></div></div>

    <div class="progress"><div id="progress-bar"></div></div>

    <h2>Analysis Results</h2>
    <div class="metrics">
        <p>RMS: <strong id="rms">N/A</strong></p>
        <p>Spectral Centroid: <strong id="centroid">N/A</strong></p>
        <p>Sentiment: <strong id="sentiment">N/A</strong></p>
        <p>Engagement Score: <strong id="engagement">N/A</strong></p>
    </div>

    <canvas id="engagementChart"></canvas>
    <button onclick="exportData()">Export Results</button>
</div>

<script>
    let wavesurfer, audioContext, analyser, meyda, microphone, model;

    const rmsDisplay = document.getElementById('rms');
    const centroidDisplay = document.getElementById('centroid');
    const sentimentDisplay = document.getElementById('sentiment');
    const engagementDisplay = document.getElementById('engagement');
    const progressBar = document.getElementById('progress-bar');
    
    const chartCtx = document.getElementById('engagementChart').getContext('2d');
    const engagementChart = new Chart(chartCtx, {
        type: 'line',
        data: { labels: [], datasets: [{ label: 'Engagement', data: [], borderColor: 'cyan' }] },
        options: { responsive: true, maintainAspectRatio: false }
    });

    // Initialize WaveSurfer.js
    wavesurfer = WaveSurfer.create({
        container: '#waveform',
        waveColor: 'lime',
        progressColor: 'green'
    });

    // Load TensorFlow model
    async function loadModel() {
        model = await tf.loadLayersModel('https://example.com/model.json'); // Replace with real model path
    }
    loadModel();

    function uploadAudio() {
        const file = document.getElementById('audio-upload').files[0];
        if (!file) return alert('Please select a valid audio file.');

        const reader = new FileReader();
        reader.onload = () => {
            wavesurfer.loadBlob(file);
            analyzeAudio(file);
        };
        reader.readAsDataURL(file);
    }

    async function analyzeAudio(file) {
        const audioBuffer = await file.arrayBuffer();
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const decodedData = await audioContext.decodeAudioData(audioBuffer);

        const rms = Math.random().toFixed(2); // Replace with Meyda RMS analysis
        const centroid = Math.random().toFixed(2);
        const sentiment = await predictSentiment(decodedData);

        updateMetrics(rms, centroid, sentiment);
    }

    function startRecording() {
        navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            microphone = audioContext.createMediaStreamSource(stream);
            microphone.connect(analyser);

            meyda = Meyda.createMeydaAnalyzer({
                audioContext, source: microphone, bufferSize: 512,
                featureExtractors: ['rms', 'spectralCentroid'],
                callback: features => {
                    updateMetrics(features.rms.toFixed(2), features.spectralCentroid.toFixed(2), "Neutral");
                }
            });
            meyda.start();
        });
    }

    function stopRecording() {
        meyda.stop();
        if (microphone) microphone.disconnect();
    }

    async function predictSentiment(audioData) {
        const tensor = tf.tensor(audioData.getChannelData(0)).reshape([1, -1]);
        const result = await model.predict(tensor).data();
        return result[0] > 0.5 ? "Positive" : "Negative";
    }

    function updateMetrics(rms, centroid, sentiment) {
        rmsDisplay.innerText = rms;
        centroidDisplay.innerText = centroid;
        sentimentDisplay.innerText = sentiment;
        engagementDisplay.innerText = (rms * 100).toFixed(0);

        engagementChart.data.labels.push(new Date().toLocaleTimeString());
        engagementChart.data.datasets[0].data.push(rms * 100);
        engagementChart.update();
    }

    function exportData() {
        const csvContent = `RMS,${rmsDisplay.innerText}\nCentroid,${centroidDisplay.innerText}\nSentiment,${sentimentDisplay.innerText}`;
        const blob = new Blob([csvContent], { type: 'text/csv' });
        const link = document.createElement('a');
        link.href = URL.createObjectURL(blob);
        link.download = 'engagement_results.csv';
        link.click();
    }
</script>
</body>
</html>
